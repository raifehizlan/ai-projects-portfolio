# LLM-gestÃ¼tzte mehrsprachige Anonymisierung von Gesundheitsdaten: Ein neuer Ansatz

Mit der zunehmenden Digitalisierung elektronischer Gesundheitsakten (EHR) wird es immer wichtiger, diese Daten unter Wahrung der PrivatsphÃ¤re der Patienten zu nutzen. In diesem Beitrag stellen wir unsere mehrsprachigen De-Identification-LÃ¶sungen vor, die mithilfe groÃŸer Sprachmodelle (LLMs) entwickelt wurden â€“ mit neuen State-of-the-Art (SOTA)-Ergebnissen.

---

## ğŸ’¡ Warum De-Identification?

Gesundheitsdaten unterliegen strengen Datenschutzgesetzen (z.â€¯B. HIPAA, DSGVO). FÃ¼r Forschung und KI-Entwicklung ist eine Anonymisierung zwingend erforderlich. Die meisten bestehenden LÃ¶sungen sind jedoch sprachspezifisch und hauptsÃ¤chlich auf Englisch optimiert.

---

## ğŸ§  LLM-In-The-Loop-Ansatz

In unserer Forschung wurden LLMs in drei zentralen Phasen eingesetzt:

1. **Generierung synthetischer Daten:** Realistisch wirkende Fake-Daten wurden fÃ¼r fehlende Kategorien erstellt.
2. **Annotation-UnterstÃ¼tzung:** LLMs beschleunigten das Labeling nach i2b2-Richtlinien.
3. **Evaluation:** Modelle wie GPT-4o wurden fÃ¼r die ÃœberprÃ¼fung der Ergebnisse eingesetzt.

Dies fÃ¼hrte zu schnellerem Training und hÃ¶herer DatenqualitÃ¤t.

---

## ğŸ§¾ Verwendete Daten und Labels

- **Englisch-Modell:** Getestet mit dem i2b2-2014-Testset; Trainingsdaten umfassten Open-Source-, synthetische und 22â€¯% proprietÃ¤re Daten.
- **Weitere Sprachen:** Englische Daten wurden mit hochwertigen medizinischen Ãœbersetzungsmodellen ins TÃ¼rkische, FranzÃ¶sische, Deutsche, Italienische, Spanische, RumÃ¤nische und Arabische Ã¼bersetzt.
- Alle Daten wurden ins BIO-Format konvertiert.

Die PHI-Kategorien (Protected Health Information) umfassten unter anderem AGE, CITY, DATE, PATIENT, DOCTOR, ORGANIZATION und PHONE.

---

## ğŸ”¬ Modell- und Trainingsdetails

- **Englisch-Modell:** Fine-Tuning auf Basis von `microsoft/deberta-v3-small`.
- **Sprachspezifische Embeddings:**
  - Deutsch: `bert-base-german-cased`
  - FranzÃ¶sisch: `camembert-bio-base`
  - TÃ¼rkisch: `bert-base-turkish-cased`
  - usw.

Alle Modelle wurden Ã¼ber 10 Epochen mit `learning_rate=2e-5`, `max_length=512` trainiert.

---

## ğŸ“Š Ergebnisse

### Leistung auf Englisch (i2b2 Testset)

| Label         | F1-Score |
|---------------|----------|
| AGE           | 0.981    |
| CITY          | 0.944    |
| ORGANIZATION  | 0.876    |
| PATIENT       | 0.967    |
| ZIP           | 0.989    |
| **Makro Ã˜**   | **0.931**|

Im Vergleich zu anderen Methoden (z.â€¯B. Khin et al., GPT-4o) erzielen wir in mehreren Kategorien neue SOTA-Werte.

### Mehrsprachige Leistung

**Makro-F1-Scores:**

- **TÃ¼rkisch:** 0.963  
- **Spanisch:** 0.957  
- **FranzÃ¶sisch:** 0.937  
- **Arabisch:** 0.922  

Besonders bei Kategorien wie DATE, PHONE und MEDICALRECORD wurde sprachunabhÃ¤ngig hohe Genauigkeit erreicht.

---

## ğŸ§© Was macht diesen Ansatz besonders?

- Mehrsprachige UnterstÃ¼tzung.
- LLM-gestÃ¼tzte Datenerweiterung und Annotation.
- Hohe QualitÃ¤t auch bei ressourcenarmen Sprachen.
- Effizientes Training kleiner, domÃ¤nenspezifischer Modelle.

---

## ğŸ“Œ Fazit und Beitrag

Diese Arbeit liefert einen wichtigen Beitrag zur Anonymisierung mehrsprachiger Gesundheitsdaten. Durch den gezielten Einsatz von LLMs ist eine prÃ¤zise De-Identification selbst in ressourcenschwachen Sprachen mÃ¶glich.

---

## ğŸ”— Quellen

- i2b2-Datensatz: [portal.dbmi.hms.harvard.edu](https://portal.dbmi.hms.harvard.edu)  
- LangTest Toolkit: [langtest.org](https://langtest.org/)  
- GPT-4o Testergebnisse: Siehe Anhang A  

---

*ğŸ“¬ Fragen oder Ã¤hnliche Projekte? Gerne austauschen!*
